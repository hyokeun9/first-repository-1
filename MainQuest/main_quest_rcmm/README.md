# π€ AutoInt+ μ‹¤ν— νκ³  (Experiment Retrospective)

λ³Έ λ¬Έμ„λ” **AutoInt+** λ¨λΈμ μ„±λ¥ ν–¥μƒκ³Ό μ•μ •μ μΈ μ¶”μ² κ²°κ³Ό ν™•λ³΄λ¥Ό μ„ν•΄ μ§„ν–‰ν• μ‹¤ν— κ³Όμ •κ³Ό κ²°κ³Όλ¥Ό μ •λ¦¬ν• κΈ°λ΅μ…λ‹λ‹¤.

---

## 1. μ‹¤ν— λ©ν‘ π―
* **μ„±λ¥ μµμ ν™”**: ν•™μµ νλΌλ―Έν„° λ° λ¨λΈ κµ¬μ΅° λ³€κ²½μ„ ν†µν• ν‰κ°€μ§€ν‘ κ°μ„ 
* **λ¦¬μ†μ¤ ν¨μ¨ν™”**: λ°μ΄ν„° νƒ€μ… μ΅°μ •μ„ ν†µν• λ©”λ¨λ¦¬ μ μ μ¨ λ° μ—°μ‚° μ†λ„ κ°μ„ 
* **μ•μ •μ„± ν™•λ³΄**: λ¨λΈ μ €μ¥ λ° λ΅λ“ λ°©μ‹ λ³€κ²½μΌλ΅ μ„λΉ™ λ‹¨κ³„μ μ¤λ¥ λ°©μ§€

---

## 2. μ£Όμ” μ‹¤ν— λ° λ³€κ²½ μ‚¬ν•­ π§

### π“‚ `autoint_mlp_train.ipynb`
* **ν•™μµ νλΌλ―Έν„° μµμ ν™”**
    * `epochs=10`, `learning_rate=1e-3`, `dropout=0.3`, `batch_size=512`, `embed_dim=16`
    * κΈ°μ΅΄ λ€λΉ„ μ—ν­ μ¦λ‰ λ° λ“λ΅­μ•„μ›ƒ μµμ ν™”λ¥Ό ν†µν•΄ κ³Όμ ν•© λ°©μ§€μ™€ ν•™μµ ν¨μ¨ μ¦λ€
    * **κ²°κ³Ό**: NDCG `0.67388`, HitRate `0.63855` λ‹¬μ„± (κΈ°λ³Έ λ¨λΈ λ€λΉ„ μ„±λ¥ ν–¥μƒ)
* **λ°μ΄ν„° ν¨μ¨μ„± κ°μ„ **
    * `int64` β†’ `int32` νƒ€μ… λ³€ν™μ„ ν†µν•΄ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μ•½ 30~40% μ κ°
    ```python
    train_df = train_df.astype({col:'int32' for col in train_df.select_dtypes('int64').columns})
    ```
* **κ°€μ¤‘μΉ μ €μ¥ λ°©μ‹ λ³€κ²½**
    * μ „μ²΄ λ¨λΈ μ €μ¥ λ€μ‹  κ°€μ¤‘μΉ(`.weights.h5`)λ§ μ €μ¥ν•μ—¬ νμΌ μ ‘κ·Ό μ¤λ¥ λ°©μ§€ λ° μ΄μ‹μ„± ν–¥μƒ

### π“‚ `autointmlp.py` (λ¨λΈ κµ¬μ΅°)
* **FeaturesEmbedding**: `int32` λ³€κ²½ ν›„μ—λ„ μ„λ² λ”© μΈλ±μ¤ κ³„μ‚°μ μ•μ •μ„±μ„ μ„ν•΄ `offsets` μ—°μ‚° λ΅μ§ μ κ²€
* **MLP Layer**: `Dropout`, `Batch Normalization` μ μ© μ‹ Training μΈμλ¥Ό λ…ν™•ν λ°μν•λ„λ΅ μμ •
* **κµ¬μ΅° κ³ λ„ν™”**: Multi-Head Self-Attention λ μ΄μ–΄ μ μ΅°μ • λ° DNN Hidden Unit μµμ ν™”
* **Predict ν•¨μ**: Batch λ‹¨μ„ μμΈ΅ μ‹ ν…μ„ μ²λ¦¬ μ•μ •ν™” λ° Top-N κ²°κ³Ό λ°ν™ λ΅μ§ κ°μ„ 

---

## 3. μ‹¤ν— κ²°κ³Ό μ”μ•½ π“

| ν•­λ© | μƒμ„Έ λ‚΄μ© | λΉ„κ³  |
| :--- | :--- | :--- |
| **ν‰κ°€ μ§€ν‘** | NDCG: **0.67388**, HitRate: **0.63855** | μ„±λ¥ μ†ν­ ν–¥μƒ |
| **λ¦¬μ†μ¤** | λ©”λ¨λ¦¬ μ‚¬μ©λ‰ **30~40% κ°μ†** | ν•™μµ μ†λ„ κ°μ„  |
| **μ•μ •μ„±** | κ°€μ¤‘μΉ μ €μ¥ λ°©μ‹ μ±„νƒ | Streamlit μ¬ν„ μ„±κ³µ |

---

## 4. νκ³  λ° κµν› (Retrospective) π’΅

1.  **λ°μ΄ν„° νƒ€μ…μ μ¤‘μ”μ„±**: λ°μ΄ν„° νƒ€μ…μ„ μ μ ν μ ν•ν•λ” κ²ƒλ§μΌλ΅λ„ ν•™μµ μ†λ„μ™€ λ¦¬μ†μ¤ κ΄€λ¦¬μ—μ„ ν° μ΄μ μ„ μ–»μ„ μ μμ—μµλ‹λ‹¤.
2.  **κµ¬μ΅°μ™€ νλΌλ―Έν„°μ μ΅°ν™”**: Attention λ μ΄μ–΄μ™€ DNN κµ¬μ΅°μ λ―Έμ„Έ μ΅°μ •μ΄ μ¶”μ² μ„±λ¥ ν–¥μƒμ— μ§κ²°λ¨μ„ ν™•μΈν–μµλ‹λ‹¤.
3.  **μ„λΉ™ ν™κ²½ κ³ λ ¤**: μ‹¤μ‹κ°„ μ¶”λ΅  ν™κ²½(Streamlit λ“±)μ—μ„λ” λ¨λΈ μ „μ²΄ μ €μ¥λ³΄λ‹¤ κ°€μ¤‘μΉ μ €μ¥μ΄ ν›¨μ”¬ μ•μ •μ μ΄λ©°, `LabelEncoder`μ μΌκ΄€μ„± μ μ§€κ°€ ν•„μμ μ…λ‹λ‹¤.
4.  **ν™•μ¥μ„±**: ν„μ¬ μ•μ •ν™”λ λ¨λΈμ„ λ°”νƒ•μΌλ΅ ν–¥ν›„ μ„λΉ„μ¤ λ°°ν¬ λ° μ‹¤μ‹κ°„ μ¶”μ² μ—”μ§„μΌλ΅ μ¦‰μ‹ ν™μ© κ°€λ¥ν•  κ²ƒμΌλ΅ κΈ°λ€λ©λ‹λ‹¤.
