# 🚀 AutoInt+ 실험 및 Streamlit 서빙 회고

본 문서는 **AutoInt+** 모델의 성능 향상과 안정적인 추천 결과 확보를 위해 진행한 실험 과정, 그리고 이를 **Streamlit**으로 시각화한 서빙 구현 내용을 정리한 기록입니다.

---

## 1. 실험 목표 🎯
* **성능 최적화**: 학습 파라미터 및 모델 구조 변경을 통한 평가지표 개선
* **리소스 효율화**: 데이터 타입 조정을 통한 메모리 점유율 및 연산 속도 개선
* **서빙 안정화**: 가중치 기반 모델 로드 및 직관적인 UI/UX 구현

---

## 2. 주요 실험 및 변경 사항 🧪

### 📂 모델 학습 및 구조 (`autoint_mlp_train.ipynb`, `autointmlp.py`)
* **학습 파라미터 최적화**
    * `epochs=10`, `learning_rate=1e-3`, `dropout=0.3`, `batch_size=512`, `embed_dim=16`
    * **결과**: NDCG `0.67388`, HitRate `0.63855` 달성 (기본 모델 대비 성능 향상)
* **데이터 효율성 개선**
    * `int64` → `int32` 타입 변환으로 메모리 사용량 30~40% 절감 및 연산 속도 개선
* **모델 저장 전략**
    * 전체 저장 방식의 오류를 방지하기 위해 가중치(`.weights.h5`)만 저장하여 재현성 확보

### 📂 Streamlit 서빙 UI 구현 (`show_st_plus.py`)
* **레이아웃 최적화 (UX 개선)**
    * **사이드바(Sidebar)**: 사용자 ID와 추천 시점(연도, 월) 입력을 분리하여 메인 화면 공간 확보
    * **컬럼 구조 (Columns)**: 사용자 프로필과 과거 이력을 병렬 배치하여 데이터 시인성 강화
* **인터랙티브 기능**
    * `st.status` & `st.spinner`: 실시간 예측 과정을 시각화하여 사용자 대기 경험 개선
    * `st.balloons`: 추천 완료 알림 시각 효과 추가
* **안정성 로직**
    * **Unseen Data 처리**: 학습 시 없던 범주형 값이 들어올 경우 `LabelEncoder`의 `fallback` 전략 적용
    * **Dummy Build**: 가중치 로드 전 더미 데이터를 통한 모델 빌드 단계 추가

---

## 3. 실험 결과 요약 📊

| 항목 | 상세 내용 | 비고 |
| :--- | :--- | :--- |
| **평가 지표** | NDCG: **0.67388**, HitRate: **0.63855** | 성능 지표 개선 |
| **리소스** | 메모리 사용량 **30~40% 감소** | 인스턴스 부하 경감 |
| **안정성** | 가중치 기반 로드 및 예외 처리 | Streamlit 실시간 추론 성공 |

---

## 4. 서비스 화면 구성 🖥️



* **Sidebar**: 👤 사용자 선택 및 📅 추천 시점 필터
* **Main Section**: 유저 정보 정보 확인 및 🌟 개인화된 Top-N 추천 리스트 출력

---

## 5. 회고 및 교훈 (Retrospective) 💡

1. **데이터 파이프라인의 일관성**: 학습 시 적용한 `int32` 변환과 범주형 인코딩 규칙이 서빙 단계에서도 동일하게 유지되어야 정확한 예측이 가능함을 확인했습니다.
2. **효율적인 리소스 관리**: 대용량 추천 시스템에서 데이터 타입을 적절히 제한하는 것이 서빙 앱의 로딩 속도에 결정적인 영향을 미칩니다.
3. **UX의 중요성**: 모델의 성능만큼이나 예측 과정을 시각화(Spinner, Status 등)하여 사용자에게 피드백을 주는 디자인 요소가 서비스 완성도를 높임을 배웠습니다.
4. **재현성 확보**: 모델 전체 저장보다 가중치 파일(`.weights.h5`)과 별도의 `LabelEncoder`를 관리하는 방식이 배포 환경에서의 오류를 최소화하는 데 효과적입니다.
