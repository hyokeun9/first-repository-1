회고

총평 및 학습 포인트

1) 데이터의 중요성 절감

- 훈련 이미지와 테스트 이미지의 퀄리티 차이, 각 클래스의 개수 불균형이 그대로 모델 성능에 반영됨.

- 데이터가 적고 다양성이 확보되지 않으면 모델이 쉽게 과적합하거나 특정 클래스만 맞추는 경향을 확인함.

2) 이미지 전처리 파이프라인 학습

- resize_images() 함수 구현을 통해 이미지 사이즈 정규화의 필요성을 체감.

- 디렉토리 구조 설계가 생각보다 중요하며 코드 오류의 빈번한 원인이 됨.

3) 모듈 임포트 및 코드 실행 순서의 중요성

- keras 미정의 오류처럼, 노트북에서는 셀 실행 순서 하나가 전체 코드 실행 성공 여부를 좌우함.

- 임포트는 반드시 첫 부분에 정리해두는 습관 필요.

4) 모델 구조 설계 경험

- CNN 기본 구조를 경험하면서 Conv → Pool → Dense 흐름 이해도 증가.

- 간단한 모델로는 정확도가 일정 수준 이상 올라가지 않는다는 한계 확인.

5) 실험 반복의 중요성

- 여러 번 TRY를 반복하면서 파라미터, 이미지 수, augment 여부에 따라 결과가 크게 달라지는 것을 실감.



 향후 개선 방향
 
1) 데이터셋 확충 및 개선

- 최소 클래스당 200장 이상 확보 recommended.

- 다양한 조명·배경·손 모양을 포함한 데이터 다양성 확보 필요.

- 테스트용 이미지는 훈련 이미지와 촬영 조건을 완전히 동일하게 맞출 것.

2) Data Augmentation 적극 활용

- ImageDataGenerator 또는 tf.keras.preprocessing 을 활용해 회전, 밝기 변화, 가우시안 노이즈, 좌우 반전 등을 적용해 과적합 방지.

3) 모델 구조 업그레이드

- 간단 CNN 대신 MobileNetV2, EfficientNetB0 같은 프리트레인 모델 활용 시 정확도 비약적 상승 가능.

4) 훈련/검증 분리 명확화

- Validation set을 따로 두고 early stopping 적용하기.

- 테스트 데이터는 절대 모델 개선 중에 사용하지 않기.

5) 코드 구조 개선

- 노트북 셀 실행 순서를 고려한 편집 필요.

- 임포트 셀을 맨 위로.

- 디렉토리 경로를 변수 한 곳에 모아 관리하기.

6) Day 2 실험으로 확장

- "가위바위보 AI 미니 데모" 웹앱 만들기(Flask/Streamlit).

- 사용자 웹캠으로 실시간 RPS 인식 모델 강화.
